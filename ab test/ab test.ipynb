{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ceca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pylab import rcParams\n",
    "from pandas import Series, DataFrame\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "import statsmodels.stats.api as sms\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815edeff",
   "metadata": {},
   "source": [
    "### 1. Before running the test\n",
    "\n",
    "#### Define sample size (check the R script for sensibility sample size and effect size). Highly recommend using Stata for it, but if not available R script will get close.\n",
    "\n",
    "#### If a true random sample is not viable, challenge the test and control group in different dimensions (skip those three tests if you can create a true random sample):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e4a843",
   "metadata": {},
   "source": [
    "#### 1.1 Z-test: two proportions test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3865495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions_ztest(p1,p2, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e950f6",
   "metadata": {},
   "source": [
    "#### 1.2 Chi-test: Categorical Value Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad80985",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.chi2_contingency(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dbca42",
   "metadata": {},
   "source": [
    "#### 1.3 t-test: Mean test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c3ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd0311",
   "metadata": {},
   "source": [
    "#### 2. After the test is run. Test the results and draw inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd1f873",
   "metadata": {},
   "source": [
    "#### 2.1 Define function for permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_func(x, nA, nB):\n",
    "   n = nA + nB\n",
    "   id_B = set(random.sample(range(n), nB))\n",
    "   id_A = set(range(n)) - id_B\n",
    "   return x.loc[id_B].mean() - x.loc[id_A].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0360936",
   "metadata": {},
   "source": [
    "####  2.2. Calculate the observed test x control difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f7831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = (df['Control0xTest1']==0) \n",
    "test = (df['Control0xTest1']==1) \n",
    "obs = 100*(np.array(df[control]['rate']) - np.array(df[test]['rate']))\n",
    "print(f'Observed difference: {obs[0]:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753ae29",
   "metadata": {},
   "source": [
    "#### where x1 and x2 being each two steps that make the rate in the previous step\n",
    "#### Create arrays to do the permutation test (p1 array with 0, p2 array with 1), then join the arrays in a pd as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = (np.array(df[control]['x1']) + np.array(df[test]['x1']) \n",
    "                 -np.array(df[control]['x2']) - np.array(df[test]['x2]))\n",
    "dif[0]\n",
    "p1 = ([0] * dif[0])\n",
    "dif_w = (np.array(df[control]['x2']) + np.array(df[test]['x2']))\n",
    "p2 = ([1] * dif_w[0])\n",
    "p1.extend(p2)\n",
    "p = pd.Series(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4de8f03",
   "metadata": {},
   "source": [
    "#### Run as many permutations as desired (change range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d899ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_diffs = [100 * perm_func(p, np.array(df[control]['x1'])[0],np.array(df[test]['x1'])[0])\n",
    "              for i in range(1000)]\n",
    "perm_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a430c",
   "metadata": {},
   "source": [
    "#### Calculate p-value for permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if obs < 0:\n",
    "    print(np.mean([diff < obs for diff in perm_diffs]))\n",
    "else:\n",
    "    print(np.mean([diff > obs for diff in perm_diffs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8106fc",
   "metadata": {},
   "source": [
    "#### p-value approximation for a binomial distribution (will be different than permutation test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38718322",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = np.array([[np.array(df[control]['x2']), \n",
    "                      np.array(df[control]['x1'])-np.array(df[control]['x2'])],\n",
    "                      [np.array(df[test]['x2']), \n",
    "                      np.array(df[test]['x1'])-np.array(df[test]['x2'])\n",
    "                      ]])\n",
    "chi2, p_value, df, _ = stats.chi2_contingency(bm)\n",
    "print(f'p=value for single sided test: {p_value/2:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f4c8af",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2788e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.hist(perm_diffs, rwidth=0.9)\n",
    "ax.axvline(x=obs_bm, lw=2)\n",
    "ax.text(-.18, 200, 'Observed\\ndifference', bbox={'facecolor':'white'})\n",
    "ax.set_xlabel('Rate (in percentage)')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
